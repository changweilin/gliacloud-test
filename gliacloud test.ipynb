{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.0\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "def ngram_probs(filename='raw_sentences.txt'):\n",
    "    with open(filename,'r') as file:\n",
    "        content_text = file.read()\n",
    "    \n",
    "    tokenizer = Tokenizer(lower=True, split=\" \")\n",
    "    tokenizer.fit_on_texts([content_text])\n",
    "    vocab = tokenizer.word_index\n",
    "    vocab_size = len(vocab)\n",
    "    \n",
    "    vocab_reverse = {}\n",
    "    vocab_keys = list(vocab.keys())\n",
    "    for vocab_word in vocab_keys:\n",
    "        vocab_index = vocab[vocab_word]\n",
    "        vocab_reverse[vocab_index] = vocab_keys[vocab_index-1]\n",
    "            \n",
    "    content_word_ids = tokenizer.texts_to_sequences([content_text])\n",
    "    content_word_ids = content_word_ids[0]\n",
    "    content_len = len(content_word_ids)\n",
    "    bigram_probs = np.zeros([vocab_size, vocab_size])\n",
    "    trigram_probs = np.zeros([vocab_size, vocab_size])\n",
    "    \n",
    "    for i in range(content_len):\n",
    "        if i-1>=0:\n",
    "            bigram_probs[content_word_ids[i]-1,content_word_ids[i-1]-1] += 1\n",
    "            trigram_probs[content_word_ids[i]-1,content_word_ids[i-1]-1] += 1\n",
    "        if i+1<content_len:\n",
    "            bigram_probs[content_word_ids[i]-1,content_word_ids[i+1]-1] += 1\n",
    "            trigram_probs[content_word_ids[i]-1,content_word_ids[i+1]-1] += 1\n",
    "        if i-2>=0:\n",
    "            trigram_probs[content_word_ids[i]-1,content_word_ids[i-2]-1] += 1\n",
    "        if i+2<content_len:\n",
    "            trigram_probs[content_word_ids[i]-1,content_word_ids[i+2]-1] += 1\n",
    "    \n",
    "    return bigram_probs, trigram_probs, vocab, vocab_reverse\n",
    "\n",
    "cnt2, cnt3, vocab ,_ = ngram_probs('E:/Raw data/test/raw_sentences.txt')\n",
    "print(cnt2[(vocab['we'], vocab['are'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5285529502007911\n"
     ]
    }
   ],
   "source": [
    "def prob3(bigram, cnt2=cnt2, cnt3=cnt3):\n",
    "    p12 = cnt2[bigram[0],bigram[1]] / cnt2[bigram[0],:].sum() + cnt2[bigram[0],bigram[1]] / cnt2[bigram[1],:].sum()\n",
    "    p123 = cnt3[:,bigram[0]] / cnt3[bigram[0],:].sum() + cnt3[:,bigram[1]] / cnt3[bigram[1],:].sum()\n",
    "    prob = p123/p12\n",
    "    return prob\n",
    "\n",
    "p = prob3([vocab['we'], vocab['are']])\n",
    "print(p[vocab['family']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are\n"
     ]
    }
   ],
   "source": [
    "def predict_max(starting, cnt2=cnt2, cnt3=cnt3):\n",
    "    list_of_words = starting\n",
    "    word_next = ''\n",
    "    while word_next=='.' or len(list_of_words)>=15:\n",
    "        p_word = []\n",
    "        n_word = []\n",
    "        for word in vocab:\n",
    "            p_word.append(p[word])\n",
    "            n_word.append(word)\n",
    "        p_max = np.array(p_word).argmax()\n",
    "        word_next = n_word[p_max]\n",
    "        list_of_words.append(word_next)\n",
    "    \n",
    "    return list_of_words\n",
    "\n",
    "sent = predict_max(['we', 'are'])\n",
    "assert sent[-1] == '.' or len(sent) <= 15\n",
    "print(' '.join(sent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
